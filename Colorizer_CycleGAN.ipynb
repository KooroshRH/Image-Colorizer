{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colorizer CycleGAN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOL2PPiPy6XUY+oss7kiOd3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KoroshRH/Image-Colorizer/blob/main/Colorizer_CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KK69G1RbE7j"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/tensorflow/examples.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "T304q9SXlS94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we set parameters for our training procedure and we can change them to see the corresponding results."
      ],
      "metadata": {
        "id": "qQc2j6g3QSkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 1\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "LAMBDA = 10\n",
        "EPOCHS = 10\n",
        "TRAIN_WINDOWS_SIZE = 200\n",
        "TEST_WINDOWS_SIZE = 50000"
      ],
      "metadata": {
        "id": "GC_KeBYKldmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n",
        "In next 4 cells, we define preprocessing section methods to resize, flip, make images gray, and normalize the values."
      ],
      "metadata": {
        "id": "sN9mlbw1Qf0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing the images to [-1, 1]\n",
        "def normalize(image):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image / 127.5) - 1\n",
        "  return image"
      ],
      "metadata": {
        "id": "4qdCyxsMmGVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_jitter(image):\n",
        "  # resizing to 256 x 256 x 3\n",
        "  image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "  # random mirroring\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "1tggkFv1mI6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "  image = random_jitter(image)\n",
        "  image = normalize(image)\n",
        "  return image"
      ],
      "metadata": {
        "id": "H_o1w3PqmLVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_grayscale(img):\n",
        "  gray = tf.image.rgb_to_grayscale(img)\n",
        "  gray = tf.concat([gray, gray, gray], axis=-1)\n",
        "  return gray"
      ],
      "metadata": {
        "id": "YfTdfRMOwBg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "We use CelebA dataset for this project, but you can use every available dataset for this section and translate their attributes to each other."
      ],
      "metadata": {
        "id": "9ZkEnuJbSpI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcs_base_dir = \"gs://celeb_a_dataset/\"\n",
        "celeb_a_builder = tfds.builder(\"celeb_a\", data_dir=gcs_base_dir, version='2.0.0')\n",
        "celeb_a_builder.download_and_prepare()"
      ],
      "metadata": {
        "id": "It1YpDuanL8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = celeb_a_builder.as_dataset(\"train[:\" + str(TRAIN_WINDOWS_SIZE) + \"]\").shuffle(BUFFER_SIZE).map(lambda celeb: celeb[\"image\"])\n",
        "train_y = celeb_a_builder.as_dataset(\"train[\" + str(TRAIN_WINDOWS_SIZE) + \":\" + str(2 * TRAIN_WINDOWS_SIZE) + \"]\").shuffle(BUFFER_SIZE).map(lambda celeb: celeb[\"image\"])\n",
        "\n",
        "test_x = celeb_a_builder.as_dataset(\"train[\" + str(2 * TRAIN_WINDOWS_SIZE) + \":\" + str(2 * TRAIN_WINDOWS_SIZE + TEST_WINDOWS_SIZE) + \"]\").shuffle(BUFFER_SIZE).map(lambda celeb: celeb[\"image\"])"
      ],
      "metadata": {
        "id": "cyFsBTydnPsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.map(make_grayscale)"
      ],
      "metadata": {
        "id": "EWvD3fXLuRTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.map(preprocess_image).batch(BATCH_SIZE)\n",
        "train_y = train_y.map(preprocess_image).batch(BATCH_SIZE)\n",
        "\n",
        "test_x = test_x.map(preprocess_image).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "-iJgFES1usLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "Here we use unet model from [pix2pix](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py), but we are going to use them in a Cyclic structure. "
      ],
      "metadata": {
        "id": "a4JYM0y6S9Rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_CHANNELS = 3\n",
        "\n",
        "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
        "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
        "\n",
        "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
        "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
      ],
      "metadata": {
        "id": "ihjQqgYG4j5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "QuWAqRDA4qQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss functions"
      ],
      "metadata": {
        "id": "WriqZQlFTmlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real, generated):\n",
        "  real_loss = loss_obj(tf.ones_like(real), real)\n",
        "  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_disc_loss * 0.5"
      ],
      "metadata": {
        "id": "HxIf50Fd4tTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(generated):\n",
        "  return loss_obj(tf.ones_like(generated), generated)"
      ],
      "metadata": {
        "id": "BzF8vOm44vFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cycle loss\n",
        "This loss function is the main idea of CycleGAN.\n",
        "In CycleGAN, we want to translate a domain's attributes to another domain and keep the main characteristics from the source domain.\n",
        "This loss function returns the difference between translated image and the original one."
      ],
      "metadata": {
        "id": "WwzvjTaNToqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_cycle_loss(real_image, cycled_image):\n",
        "  loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "\n",
        "  return LAMBDA * loss"
      ],
      "metadata": {
        "id": "eIxcI89y4xD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_loss(real_image, same_image):\n",
        "  loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "  return LAMBDA * 0.5 * loss"
      ],
      "metadata": {
        "id": "yPakAo3N4zak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "5y-AG-MoUlLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator_g_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "generator_f_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "\n",
        "discriminator_x_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "discriminator_y_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)"
      ],
      "metadata": {
        "id": "CxNyumXR43ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(real_x, real_y):\n",
        "  # persistent is set to True because the tape is used more than\n",
        "  # once to calculate the gradients.\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "    # Generator G translates X -> Y\n",
        "    # Generator F translates Y -> X.\n",
        "\n",
        "    fake_y = generator_g(real_x, training=True)\n",
        "    cycled_x = generator_f(fake_y, training=True)\n",
        "\n",
        "    fake_x = generator_f(real_y, training=True)\n",
        "    cycled_y = generator_g(fake_x, training=True)\n",
        "\n",
        "    # same_x and same_y are used for identity loss.\n",
        "    same_x = generator_f(real_x, training=True)\n",
        "    same_y = generator_g(real_y, training=True)\n",
        "\n",
        "    disc_real_x = discriminator_x(real_x, training=True)\n",
        "    disc_real_y = discriminator_y(real_y, training=True)\n",
        "\n",
        "    disc_fake_x = discriminator_x(fake_x, training=True)\n",
        "    disc_fake_y = discriminator_y(fake_y, training=True)\n",
        "\n",
        "    # calculate the loss\n",
        "    gen_g_loss = generator_loss(disc_fake_y)\n",
        "    gen_f_loss = generator_loss(disc_fake_x)\n",
        "\n",
        "    total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
        "\n",
        "    # Total generator loss = adversarial loss + cycle loss\n",
        "    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
        "    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
        "\n",
        "    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
        "    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
        "\n",
        "  # Calculate the gradients for generator and discriminator\n",
        "  generator_g_gradients = tape.gradient(total_gen_g_loss, generator_g.trainable_variables)\n",
        "  generator_f_gradients = tape.gradient(total_gen_f_loss, generator_f.trainable_variables)\n",
        "\n",
        "  discriminator_x_gradients = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)\n",
        "  discriminator_y_gradients = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)\n",
        "\n",
        "  # Apply the gradients to the optimizer\n",
        "  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n",
        "  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))\n",
        "  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
        "  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))"
      ],
      "metadata": {
        "id": "cXtgCT7_5G7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_celeb = next(iter(test_x))\n",
        "gray_sample = make_grayscale(sample_celeb)"
      ],
      "metadata": {
        "id": "VCvHLcot5QCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper funtion\n",
        "This function allow us to display gray, colorized, and the original picture and compare them.\n"
      ],
      "metadata": {
        "id": "jkpsfZdJUqT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(model, test_input, ground_truth):\n",
        "  prediction = model(test_input)\n",
        "\n",
        "  plt.figure(figsize=(12, 12))\n",
        "\n",
        "  display_list = [test_input[0], prediction[0], ground_truth[0]]\n",
        "  title = ['Input Image', 'Predicted Image', 'Original Colored Image']\n",
        "\n",
        "  for i in range(3):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "eIxjLa925AAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  n = 0\n",
        "  for image_x, image_y in tf.data.Dataset.zip((train_x, train_y)):\n",
        "    train_step(image_x, image_y)\n",
        "    if n % 10 == 0:\n",
        "      print ('.', end='')\n",
        "    n += 1\n",
        "\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  print(str(epoch + 1) + \"/\" + str(EPOCHS))\n",
        "  generate_images(generator_g, gray_sample, sample_celeb)"
      ],
      "metadata": {
        "id": "_rHioau85OrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test in test_x.take(5):\n",
        "  gray_sample = make_grayscale(test)\n",
        "  generate_images(generator_g, gray_sample, test)"
      ],
      "metadata": {
        "id": "uK86CkE7MxeO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}